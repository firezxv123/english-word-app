#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å®Œæ•´çš„å…­å¹´çº§è¯åº“å¯¼å…¥è„šæœ¬
åŸºäº2024å¹´æœ€æ–°äººæ•™ç‰ˆPEPå…­å¹´çº§æ•™æï¼ŒåŒ…å«å®Œæ•´çš„è¯æ±‡å†…å®¹
"""

import sys
import os
import json
sys.path.insert(0, os.path.abspath('.'))

from app import create_app, db
from app.models.word import Word

def import_complete_grade6_words():
    """å¯¼å…¥å®Œæ•´çš„å…­å¹´çº§è¯æ±‡"""
    app = create_app()
    
    with app.app_context():
        print("ğŸš€ å¼€å§‹å¯¼å…¥å®Œæ•´çš„å…­å¹´çº§è¯åº“")
        print("="*50)
        
        # è¦å¯¼å…¥çš„å…­å¹´çº§è¯æ±‡æ–‡ä»¶
        grade6_files = [
            'grade6_words_complete.json',  # æ–°çš„å®Œæ•´è¯åº“
            'grade6_words_additional.json',  # ä¹‹å‰çš„è¡¥å……è¯åº“
            'grade6_words_extended.json'     # ä¹‹å‰çš„æ‰©å±•è¯åº“
        ]
        
        total_imported = 0
        total_updated = 0
        
        for file_name in grade6_files:
            file_path = os.path.join(os.getcwd(), file_name)
            
            if not os.path.exists(file_path):
                print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
                continue
                
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {file_name}")
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    words_data = json.load(f)
                
                imported = 0
                updated = 0
                
                for word_data in words_data:
                    word = word_data.get('word', '').strip()
                    chinese_meaning = word_data.get('chinese_meaning', '').strip()
                    grade = word_data.get('grade', 6)
                    unit = word_data.get('unit', 1)
                    
                    if not word or not chinese_meaning:
                        print(f"âš ï¸  è·³è¿‡ç©ºè¯æ±‡: {word_data}")
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„è¯æ±‡
                    existing_word = Word.query.filter_by(
                        word=word, 
                        grade=grade
                    ).first()
                    
                    if existing_word:
                        # æ›´æ–°ç°æœ‰è¯æ±‡
                        if existing_word.chinese_meaning != chinese_meaning or existing_word.unit != unit:
                            existing_word.chinese_meaning = chinese_meaning
                            existing_word.unit = unit
                            updated += 1
                            print(f"âœï¸  æ›´æ–°: {word} -> {chinese_meaning} ({grade}å¹´çº§ç¬¬{unit}å•å…ƒ)")
                    else:
                        # æ·»åŠ æ–°è¯æ±‡
                        new_word = Word(
                            word=word,
                            chinese_meaning=chinese_meaning,
                            grade=grade,
                            unit=unit
                        )
                        db.session.add(new_word)
                        imported += 1
                        print(f"â• æ–°å¢: {word} -> {chinese_meaning} ({grade}å¹´çº§ç¬¬{unit}å•å…ƒ)")
                
                total_imported += imported
                total_updated += updated
                
                print(f"ğŸ“Š {file_name}: æ–°å¢ {imported} ä¸ªï¼Œæ›´æ–° {updated} ä¸ª")
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # æäº¤æ‰€æœ‰æ›´æ”¹
        try:
            db.session.commit()
            print(f"\nâœ… å¯¼å…¥å®Œæˆ!")
            print(f"ğŸ“ˆ æ€»è®¡: æ–°å¢ {total_imported} ä¸ªè¯æ±‡ï¼Œæ›´æ–° {total_updated} ä¸ªè¯æ±‡")
            
            # ç»Ÿè®¡å…­å¹´çº§è¯æ±‡æ€»æ•°
            grade6_total = Word.query.filter_by(grade=6).count()
            print(f"ğŸ“š å…­å¹´çº§è¯æ±‡æ€»æ•°: {grade6_total} ä¸ª")
            
            # æŒ‰å•å…ƒç»Ÿè®¡
            print(f"\nğŸ“‹ æŒ‰å•å…ƒåˆ†å¸ƒ:")
            for unit in range(1, 11):  # å…­å¹´çº§æœ€å¤š10ä¸ªå•å…ƒ
                count = Word.query.filter_by(grade=6, unit=unit).count()
                if count > 0:
                    print(f"   ç¬¬{unit}å•å…ƒ: {count} ä¸ªè¯æ±‡")
                    
        except Exception as e:
            db.session.rollback()
            print(f"âŒ æäº¤å¤±è´¥: {str(e)}")

def check_grade6_completeness():
    """æ£€æŸ¥å…­å¹´çº§è¯åº“å®Œæ•´æ€§"""
    app = create_app()
    
    with app.app_context():
        print("\nğŸ” æ£€æŸ¥å…­å¹´çº§è¯åº“å®Œæ•´æ€§")
        print("="*40)
        
        total = Word.query.filter_by(grade=6).count()
        print(f"ğŸ“Š å…­å¹´çº§æ€»è¯æ±‡æ•°: {total}")
        
        # åˆ†æè¯æ±‡åˆ†å¸ƒ
        units_distribution = {}
        for unit in range(1, 11):
            count = Word.query.filter_by(grade=6, unit=unit).count()
            if count > 0:
                units_distribution[unit] = count
        
        print(f"ğŸ“‹ å•å…ƒåˆ†å¸ƒ: {units_distribution}")
        
        # è¯„ä¼°å®Œæ•´æ€§
        if total >= 160:
            status = "âœ… ä¼˜ç§€"
        elif total >= 120:
            status = "ğŸŸ¨ è‰¯å¥½"
        elif total >= 80:
            status = "ğŸŸ§ éœ€è¦è¡¥å……"
        else:
            status = "âŒ ä¸¥é‡ä¸è¶³"
            
        print(f"ğŸ“ˆ å®Œæ•´æ€§è¯„ä¼°: {status} ({total}/160-180ä¸ªç›®æ ‡è¯æ±‡)")
        
        # æ˜¾ç¤ºä¸€äº›æ ·ä¾‹è¯æ±‡
        sample_words = Word.query.filter_by(grade=6).limit(10).all()
        print(f"\nğŸ“– è¯æ±‡æ ·ä¾‹:")
        for word in sample_words:
            print(f"   {word.word} -> {word.chinese_meaning} (ç¬¬{word.unit}å•å…ƒ)")

def clean_duplicate_words():
    """æ¸…ç†é‡å¤è¯æ±‡"""
    app = create_app()
    
    with app.app_context():
        print("\nğŸ§¹ æ¸…ç†é‡å¤è¯æ±‡")
        print("="*30)
        
        # æŸ¥æ‰¾é‡å¤çš„è¯æ±‡ï¼ˆç›¸åŒçš„wordå’Œgradeï¼‰
        duplicates = db.session.query(Word.word, Word.grade)\
            .group_by(Word.word, Word.grade)\
            .having(db.func.count(Word.id) > 1)\
            .all()
        
        if not duplicates:
            print("âœ… æ²¡æœ‰å‘ç°é‡å¤è¯æ±‡")
            return
            
        print(f"âš ï¸  å‘ç° {len(duplicates)} ç»„é‡å¤è¯æ±‡")
        
        cleaned_count = 0
        for word_text, grade in duplicates:
            # è·å–æ‰€æœ‰é‡å¤çš„è®°å½•
            duplicate_records = Word.query.filter_by(word=word_text, grade=grade).all()
            
            if len(duplicate_records) <= 1:
                continue
                
            # ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œåˆ é™¤å…¶ä½™çš„
            keep_record = duplicate_records[0]
            for record in duplicate_records[1:]:
                print(f"ğŸ—‘ï¸  åˆ é™¤é‡å¤: {record.word} (ID: {record.id})")
                db.session.delete(record)
                cleaned_count += 1
        
        if cleaned_count > 0:
            db.session.commit()
            print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªé‡å¤è¯æ±‡")
        else:
            print("âœ… æ²¡æœ‰é‡å¤è¯æ±‡éœ€è¦æ¸…ç†")

if __name__ == "__main__":
    print("ğŸ¯ å…­å¹´çº§è¯åº“å®Œæ•´åŒ–ç¨‹åº")
    print("æ ¹æ®2024å¹´æœ€æ–°äººæ•™ç‰ˆPEPæ•™ææ ‡å‡†")
    print()
    
    # 1. æ¸…ç†é‡å¤è¯æ±‡
    clean_duplicate_words()
    
    # 2. å¯¼å…¥å®Œæ•´è¯åº“
    import_complete_grade6_words()
    
    # 3. æ£€æŸ¥å®Œæ•´æ€§
    check_grade6_completeness()
    
    print("\nğŸ‰ å…­å¹´çº§è¯åº“æ›´æ–°å®Œæˆ!")
    print("è¯åº“æ¥æº: 2024å¹´äººæ•™ç‰ˆPEPå…­å¹´çº§ä¸Šä¸‹å†Œæ•™æ")
    print("åŒ…å«: åŸºç¡€è¯æ±‡ã€é‡ç‚¹å¥å‹ã€è¯­æ³•è¦ç‚¹")